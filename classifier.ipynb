{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YwvHf68BRlfT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.datasets.folder import DatasetFolder\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "from torchvision.models import googlenet, GoogLeNet_Weights\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from torchvision.models import resnext50_32x4d, ResNeXt50_32X4D_Weights\n",
    "from skimage.io import imread\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from flopth import flopth\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PqqeiVvDS6wi"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "DATA_DIR = './'\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root_dir, test_size=0.2, transform=None, test = False):\n",
    "        \n",
    "        #Collect all samples from our dataset\n",
    "        #Note that our dataset contains 5000 true and 5000 photoshopped images\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.class_folders = ['originals', 'photoshops']\n",
    "        self.samples = []\n",
    "\n",
    "        for class_folder in self.class_folders:\n",
    "            class_path = os.path.join(self.root_dir, class_folder)\n",
    "            class_label = self.class_folders.index(class_folder)\n",
    "            for file_name in os.listdir(class_path):\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                self.samples.append((file_path, class_label))\n",
    "        \n",
    "        # randomly split into train and test sets\n",
    "        train_samples, test_samples = train_test_split(self.samples, test_size=test_size)\n",
    "        \n",
    "        #Subsample data as needed for experiments\n",
    "        train_samples = train_samples[:1600]\n",
    "        test_samples = test_samples[:400]\n",
    "        \n",
    "        #Label data\n",
    "        if test:\n",
    "            self.samples = test_samples\n",
    "            self.train = False\n",
    "        else:\n",
    "            self.samples = train_samples\n",
    "            self.train = True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path, class_label = self.samples[index]\n",
    "        image = Image.open(file_path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "CMCHxf-jTe7W",
    "outputId": "2ca3a3e9-1f15-4c9a-9f50-b8583274bb82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "#transform and split data\n",
    "my_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #299, 299 for inception\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = MyDataset(DATA_DIR, test_size=0.2, transform=my_transform, test = False)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = MyDataset(DATA_DIR, test_size=0.2, transform=my_transform, test = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPeGoQ9sU46q",
    "outputId": "afd045df-c325-4b44-9886-40ec0cd18cc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth\" to C:\\Users\\Nebbocaj/.cache\\torch\\hub\\checkpoints\\resnext50_32x4d-1a0047aa.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 95.8M/95.8M [01:14<00:00, 1.35MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.26651G 25.0289M\n"
     ]
    }
   ],
   "source": [
    "#Call model\n",
    "arch = \"resnext\"\n",
    "\n",
    "if arch == \"inceptionv3\":\n",
    "    model = inception_v3(weights=Inception_V3_Weights.DEFAULT).to(device)\n",
    "elif arch == \"resnet18\":\n",
    "    model = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)\n",
    "elif arch == \"resnet34\":\n",
    "    model = resnet34(weights=ResNet34_Weights.DEFAULT).to(device)\n",
    "elif arch == \"resnet50\":\n",
    "    model = resnet50(weights=ResNet50_Weights.DEFAULT).to(device)\n",
    "elif arch == \"googlenet\":\n",
    "    model = googlenet(weights=GoogLeNet_Weights.DEFAULT).to(device)\n",
    "elif arch == \"vit\":\n",
    "    model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT).to(device)\n",
    "elif arch == \"dense\":\n",
    "    model = densenet121(weights=DenseNet121_Weights.DEFAULT).to(device)\n",
    "elif arch == \"resnext\":\n",
    "    model = resnext50_32x4d(weights=ResNeXt50_32X4D_Weights.DEFAULT).to(device)\n",
    "\n",
    "#Get parameters\n",
    "flops, params = flopth(model, in_size=((3, 224, 224),))\n",
    "print(flops, params)\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr,momentum=momentum)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "4KsoBcJzVf43",
    "outputId": "db2a47bb-cb93-4098-b47c-de6d50450e08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 Batch number 0\n"
     ]
    }
   ],
   "source": [
    "all_acc = []\n",
    "for epoch_num in range(0, epochs):\n",
    "    model.train()\n",
    "    epoch_total_loss = 0\n",
    "    train_predictions = []\n",
    "    train_labels = []\n",
    "    for batch_num, (inp, target) in enumerate(train_loader):\n",
    "        if batch_num % 10 == 0:\n",
    "            print(\"EPOCH\", epoch_num, \"Batch number\", batch_num)\n",
    "        train_labels+=target\n",
    "        optimizer.zero_grad()\n",
    "        if arch == \"inceptionv3\":\n",
    "            output, _ = model(inp.to(device))\n",
    "        else: \n",
    "            output = model(inp.to(device))\n",
    "        batch_loss = criterion(output,target.to(device))\n",
    "        _, prediction = torch.max(output, dim=1)\n",
    "        train_predictions += prediction.detach().tolist()\n",
    "        epoch_total_loss += batch_loss.item()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    train_accuracy = metrics.accuracy_score(train_labels, train_predictions)\n",
    "    all_acc.append(train_accuracy)\n",
    "    print(\"Train Accuracy = %0.2f\" % (train_accuracy))\n",
    "\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for batch_num, (inp, target) in enumerate(test_loader):\n",
    "        labels+=target\n",
    "        batch_prediction = model(inp.to(device))\n",
    "        _, batch_prediction = torch.max(batch_prediction, dim=1)\n",
    "        predictions += batch_prediction.detach().tolist()\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    print(\"Test Accuracy = %0.2f\" % (accuracy))\n",
    "    confusion = metrics.confusion_matrix(labels, predictions)\n",
    "    \n",
    "    try:\n",
    "        print(confusion)\n",
    "        f1_score = sklearn.metrics.f1_score(labels, predictions)\n",
    "        print(f1_score)\n",
    "        recall = sklearn.metrics.recall_score(labels, predictions)\n",
    "    except:\n",
    "        pass\n",
    "print(all_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
